{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9uo6vsjao0H",
        "outputId": "3e602d46-df50-4bb4-950e-0f52574c7148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 878 kB 30.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 26.1 MB 49.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 38.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 37.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 23.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.3 MB 55.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 859 kB 53.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 40 kB 22 kB/s \n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 9.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 42.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 510 kB 42.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 42.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 51.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 48.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 654 kB 43.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 42.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 37.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 219 kB 43.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.5 MB/s \n",
            "\u001b[?25h  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.21.2 which is incompatible.\n",
            "xarray 0.20.2 requires pandas>=1.1, but you have pandas 0.25.3 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.18.0 which is incompatible.\n",
            "thinc 8.1.0 requires pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4, but you have pydantic 1.3 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires numpy>=1.20, but you have numpy 1.18.0 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.0 which is incompatible.\n",
            "spacy 3.4.0 requires pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4, but you have pydantic 1.3 which is incompatible.\n",
            "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.4.1 which is incompatible.\n",
            "prophet 1.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.18.0 which is incompatible.\n",
            "jaxlib 0.3.14+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.0 which is incompatible.\n",
            "jaxlib 0.3.14+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.14 requires numpy>=1.19, but you have numpy 1.18.0 which is incompatible.\n",
            "jax 0.3.14 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.21.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.22.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.18.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !pip install --q deeppavlov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maOb90c0cp5P",
        "outputId": "e0635607-84fa-401d-ba34-8000c378f95b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-28 15:06:30.187 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'squad_torch_bert' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/squad/squad_torch_bert.json'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.6.0\n",
            "  Downloading transformers-4.6.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 29.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (1.18.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (0.0.35)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (4.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (4.62.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 47.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (2.22.0)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (2022.6.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.6.0) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.6.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.6.0) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0) (7.1.2)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 tokenizers-0.10.3 transformers-4.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8 MB 15 kB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.18.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.0+cu113\n",
            "    Uninstalling torch-1.12.0+cu113:\n",
            "      Successfully uninstalled torch-1.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.0+cu113 requires torch==1.12.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.6.0 which is incompatible.\n",
            "fastai 2.7.7 requires torch<1.13,>=1.7, but you have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchvision==0.7.0\n",
            "  Downloading torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 23.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (1.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (1.18.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (7.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->torchvision==0.7.0) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.0+cu113\n",
            "    Uninstalling torchvision-0.13.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.7 requires torch<1.13,>=1.7, but you have torch 1.6.0 which is incompatible.\n",
            "fastai 2.7.7 requires torchvision>=0.8.2, but you have torchvision 0.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torchvision-0.7.0\n"
          ]
        }
      ],
      "source": [
        "# !python -m deeppavlov install squad_torch_bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9QoDiTFb2qF",
        "outputId": "429dd8e1-99bf-4916-ee16-6ead6c59e603"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-28 18:21:42.147 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/v1/squad/squad_torch_bert.tar.gz download because of matching hashes\n",
            "2022-07-28 18:21:42,147 - deeppavlov.download - INFO - Skipped http://files.deeppavlov.ai/v1/squad/squad_torch_bert.tar.gz download because of matching hashes\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Package perluniprops is already up-to-date!\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
            "2022-07-28 18:21:46.649 INFO in 'deeppavlov.models.torch_bert.torch_transformers_squad'['torch_transformers_squad'] at line 246: From pretrained bert-base-uncased.\n",
            "2022-07-28 18:21:46,649 - deeppavlov.models.torch_bert.torch_transformers_squad - INFO - From pretrained bert-base-uncased.\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2022-07-28 18:21:51.547 INFO in 'deeppavlov.models.torch_bert.torch_transformers_squad'['torch_transformers_squad'] at line 275: Load path /root/.deeppavlov/models/squad_torch_bert/bert-base-uncased/model is given.\n",
            "2022-07-28 18:21:51,547 - deeppavlov.models.torch_bert.torch_transformers_squad - INFO - Load path /root/.deeppavlov/models/squad_torch_bert/bert-base-uncased/model is given.\n",
            "2022-07-28 18:21:51.554 INFO in 'deeppavlov.models.torch_bert.torch_transformers_squad'['torch_transformers_squad'] at line 282: Load path /root/.deeppavlov/models/squad_torch_bert/bert-base-uncased/model.pth.tar exists.\n",
            "2022-07-28 18:21:51,554 - deeppavlov.models.torch_bert.torch_transformers_squad - INFO - Load path /root/.deeppavlov/models/squad_torch_bert/bert-base-uncased/model.pth.tar exists.\n",
            "2022-07-28 18:21:51.559 INFO in 'deeppavlov.models.torch_bert.torch_transformers_squad'['torch_transformers_squad'] at line 283: Initializing `TorchTransformersSquad` from saved.\n",
            "2022-07-28 18:21:51,559 - deeppavlov.models.torch_bert.torch_transformers_squad - INFO - Initializing `TorchTransformersSquad` from saved.\n",
            "2022-07-28 18:21:51.565 INFO in 'deeppavlov.models.torch_bert.torch_transformers_squad'['torch_transformers_squad'] at line 286: Loading weights from /root/.deeppavlov/models/squad_torch_bert/bert-base-uncased/model.pth.tar.\n",
            "2022-07-28 18:21:51,565 - deeppavlov.models.torch_bert.torch_transformers_squad - INFO - Loading weights from /root/.deeppavlov/models/squad_torch_bert/bert-base-uncased/model.pth.tar.\n",
            "2022-07-28 18:21:56.384 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 102: Model was successfully initialized! Model summary:\n",
            " BertForQuestionAnswering(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n",
            "2022-07-28 18:21:56,384 - deeppavlov.core.models.torch_model - INFO - Model was successfully initialized! Model summary:\n",
            " BertForQuestionAnswering(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from deeppavlov import configs, build_model\n",
        "\n",
        "model = build_model(configs.squad.squad_torch_bert, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcCSckqgc2Rd",
        "outputId": "bbadc904-b962-488b-eb46-c00f160392aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A.PUSHKIN THE FISHERMAN AND THE GOLDFISH ~<V вЂў > A. PUSHKIN THE FISHERMAN AND THE GOLDFISH MK 'AVMmwl mm wm There once lived an old man and his goodwife On the shore of the deep blue ocean; They lived in a tumble-down hovel For thirty-three summers and winters. The old man used to fish for his living, And his wife spun yarn on her distaff. He once cast his net in the ocean, And pulled it up with mud from the bottom; He again cast his net in the ocean, And this time caught nothing but seaweed; When he cast his net for the third time, One fish was all that he landed, No common fish, though, but a goldfish. Now the goldfish began to implore him, And it spoke like a real human being: вЂњPut me back, old man, into the oceanвЂ” I will pay you a right royal ransom, I will give you whatever you ask me.вЂќ The old man was astonished and frightenedвЂ” HeвЂ™d been fishing for thirty-three summers, But had not heard of any fish talking. So with care he untangled the goldfish And tenderly said as he did so: вЂњGod bless you, my dear little goldfish! Thank you kindly, I donвЂ™t want your ransom. Go back to your home in the ocean, And roam where you will without hindrance.вЂќ To his wife the old fisherman hastened To tell her about this great marvel. вЂњI caught only one fish this morningвЂ” A goldfish it was, most uncommon; It spoke like a Christian, and begged me To put it back into the ocean, And promised to pay a rich ransom, To give me whatever I asked for. But how could I ask for a ransom? I released it without any payment.вЂќ His wife started scolding her husband: вЂњOh you simpleton! Oh you great silly! CouldnвЂ™t make a mere fish pay a ransom! You at least might have asked for a wash-tubвЂ” For ours is all falling to pieces! 4 The old man returned to the seashore, Where the blue waves were frolicking lightly. He called out aloud for the goldfish, And the goldfish swam up and demanded: вЂњWhat is it, old man, you are wanting?вЂќ With a bow, the old man said in answer: вЂњForgive me, Your Majesty Goldfish! My old woman has scolded me roundlyвЂ” WonвЂ™t leave me alone for a minute, She says that she wants a new wash-tub, For ours is all falling to pieces.вЂќ The goldfish murmured in answer: вЂњDo not worry, go home, God be with youвЂ” Very well, you shall have a new wash-tub.вЂќ To his wife the old fisherman hastened, And beholdвЂ”there it was, the new wash-tub. But she scolded him louder than ever: вЂњOh you simpleton! Oh you great silly! To ask for a tubвЂ”a mere wash-tub! What good can you get from a wash-tub? Return to the goldfish, you silly, Bow down low and ask for a cottage.вЂќ (5 Again he went back to the seashore, And this time the blue sea was troubled. He called out aloud for the goldfish, And the goldfish swam up and demanded: вЂњWhat is it, old man, you are wanting?вЂќ With a bow, the old man said in answer: вЂњForgive me, Your Majesty Goldfish! My old woman is angrier than ever, WonвЂ™t leave me alone for a minuteвЂ” The old scold says she wants a new cottage.вЂќ The goldfish murmured in answer: вЂњDo not worry, go home, God be with you! So be it! YouвЂ™ll have a new cottage! вЂќ So back the old man turned his footsteps; Not a sign did he see of his hovel. In its place stood a new gabled cottage, With a chimney of brick, newly whitewashed, A fence with oak gates stood around it; And there sat his wife at a window; When she saw him, she scolded him roundly: вЂњOh you simpleton! Oh you great silly! To ask for no more than a cottage! Go and bow to the goldfish, and tell it That IвЂ™m tired of being a peasant, That I want to be made a fine lady.вЂќ 8 The old man then returned to the seashore, Where the ocean was restlessly foaming, He called out aloud for the goldfish. The goldfish swam up and demanded: вЂњWhat is it, old man, you are wanting?вЂќ With a bow, the old man said in answer: вЂњForgive me, Your Majesty Goldfish! My old woman is madder than ever, She gives me no rest for a second, Says sheвЂ™s tired of being a peasant, And wants to be made a fine lady.вЂќ The goldfish murmured in answer: вЂњDo not worry, go home, God be with you. Very well, a fine lady she shall be.вЂќ To his wife the old fisherman hastened. And what did he see?-a tall mansion; On its white marble stairsвЂ”his old woman. She was wearing a rich sable jacket, And a head-dress, in gold all embroidered; Her neck was with pearls heavy laden; She wore golden rings on her fingers; She was shod in the softest red leather; Zealous servants bowed meekly before her, As she cuffed them and rated them roundly. The old man then approached his wife, saying: вЂњGreetings, your ladyship, greetings, fine lady! Now I hope that your soul is contented! вЂќ She angrily bade him be silent And sent him to serve in the stables. 10 First a week slowly passed, then another, The old woman grew prouder than ever. One morning she sent for her husband, And said: вЂњBow to the goldfish and tell it I am tired of being a lady, And I want to be made a Tsaritsa.вЂќ Her husband implored her in terror, Saying: вЂњWoman-youвЂ™ve surely gone crazy! You canвЂ™t even talk like a lady! YouвЂ™d be mocked at all over the kingdom! вЂќ His old woman grew madder than ever, Slapped his face and then shouted in passion: вЂњHow dare you, muzhik, stand and argue, Stand and argue with me, a fine lady? Go at onceвЂ”if you donвЂ™t, then I warn you, YouвЂ™ll be dragged to the shore, willy-nilly.вЂќ The old man went down to the seashore (The ocean was swollen and sullen). He called out aloud for the goldfish, And the goldfish swam up and demanded: вЂњWhat is it, old man, you are wanting?вЂќ With a bow, the old man said in answer: вЂњForgive me, Your Majesty Goldfish! Again my old womanвЂ™s gone crazy! Now sheвЂ™s tired of being a lady! She wants to be made a Tsaritsa.вЂќ The goldfish murmured in answer: вЂњDo not worry, go home, God be with you! Very well! She shall be a Tsaritsa! в– iUrTV -1 1 lt . ! j V J&jf l V / v / _J i tin B ' il ml T _ Ir i/ jВ« g yrCo sijb'i vy , I To his wife the old fisherman hastened, And what did he see? A grand palace; In the palace he saw his old woman, At the table she sat, a Tsaritsa, Attended by nobles and boyards; They were pouring choice wines in her goblet, She was nibbling sweet gingerbread wafers; Around her, grim guards stood in silence, With halberds upon their broad shoulders. The old man was aghast when he saw this, He bowed to her feet and said humbly: вЂњGreetings, Oh mighty Tsaritsa! Now I hope that your soul is contented! вЂќ l.i But she gave not a glance at her husbandвЂ” She ordered him thrust from her presence. The boyards and nobles all hastened And drove him with blows from the chamber; The guards at the door waved their halberds And threatened to cut him to pieces. All the people derided him, saying: вЂњServes you right, now, you ill-bred old fellow. You churl-this will teach you a lesson To keep to your station in future! First a week slowly passed, then another; The old woman grew prouder than ever. She sent for her husband one morning, l'. And her chamberlain haled him before her. The old woman spoke thus to her husband: вЂњGo, bow to the goldfish, and tell it That IвЂ™m tired of being Tsaritsa, Of the seas I want to be mistress, With my home in the blue ocean waters; The goldfish I want for my servant To do my commands and my errands.вЂќ The old man durst not contradict her, Nor open his lips to make answer. He sadly set out for the seashore. A tempest raged over the ocean, Its waters were swollen and angry, Its billows were boiling with fury. He called out aloud for the goldfish. The goldfish swam up and demanded: вЂњWhat is it, old man, you are wanting?вЂќ With a bow, the old man said in answer: вЂњForgive me, Your Majesty Goldfish! What shall I do with my cursed old woman? She is tired of being Tsaritsa, Of the seas she now wants to be mistress, With her home in the blue ocean waters; She wants you to be her own servant, To do her commands and her errands.вЂќ Not a word spoke the goldfish in answer, It just swished its tail, and in silence вЂў Disappeared in the depths of the ocean. He waited in vain for an answer, And at last turned his steps to the palace; And beholdвЂ”there again stood his hovel; On the doorstep sat his old woman, With the same broken wash-tub before her. Translated from the Russian by Louis Zelikoff Illustrated by B. Dekhteryov WOGRtSSPUBLISHERS <вЂ™вЂў' ,> ; t. MOSCOW ; a. nywKHH CKA3KA O PWBART H PtIBKH Ha am/utucKOM jt3biKe First printing 1958 Second printing 1969 Third printing 1973 . V . Fourth' printing 1980 r yuA. 70802-232 016(01)-80 127-80 Milled in the Onion of Soviet Socialist Republics\n"
          ]
        }
      ],
      "source": [
        "text = open('/content/THE FISHERMAN AND THE GOLDFISH - SOVIET CHILDREN\\'S BOOK_djvu.txt', 'rb').read().decode(encoding='cp1251')\n",
        "text = ' '.join(text.split())\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hOGR7nI4n1lP"
      },
      "outputs": [],
      "source": [
        "from transformers import FSMTForConditionalGeneration, FSMTTokenizer\n",
        "\n",
        "en_ru = \"facebook/wmt19-en-ru\"\n",
        "tokenizer_ru = FSMTTokenizer.from_pretrained(en_ru)\n",
        "to_ru = FSMTForConditionalGeneration.from_pretrained(en_ru)\n",
        "\n",
        "ru_en = \"facebook/wmt19-ru-en\"\n",
        "tokenizer_en = FSMTTokenizer.from_pretrained(ru_en)\n",
        "to_en = FSMTForConditionalGeneration.from_pretrained(ru_en)\n",
        "\n",
        "def translation(text, model, tokenizer):\n",
        "    input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(input_ids)\n",
        "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    \n",
        "    return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubdI7CMVq-Rq",
        "outputId": "9f841177-3c56-442a-84b3-76005fd4a3eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['a library for NLP and dialog systems'], [14], [200928.578125]]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model(['DeepPavlov is a library for NLP and dialog systems.'], ['What is DeepPavlov?'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIpyxCvQVGh8",
        "outputId": "55be520f-c24c-4b61-f5d1-a4cfa97468f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['A.PUSHKIN THE FISHERMAN AND THE GOLDFISH'], [0], [24920.771484375]]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model([text], ['Who is author?'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "ZpsjF5GWVqok",
        "outputId": "c0f40ed3-b566-4ed8-9028-ef3fab225876"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6fd6554cff2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Кто автор?'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtranslation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: translation() missing 1 required positional argument: 'tokenizer'"
          ]
        }
      ],
      "source": [
        "s = 'Кто автор?'\n",
        "translation(s, to_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbbwD0pEWZw7",
        "outputId": "5aeb3a9e-78c9-4e3a-cda1-02930d9cd5d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['A.PUSHKIN THE FISHERMAN AND THE GOLDFISH'], [0], [23221.205078125]]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model([text], [translation(s, to_en, tokenizer_en)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMHKeadkWgqq",
        "outputId": "8561de69-66bd-4fe7-992c-7f00cd108004"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['frightened'], [842], [9.871175765991211]]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model([text], [translation('Почему разгневалась рыбка?', to_en, tokenizer_en)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJWsbInJWqdF",
        "outputId": "c76aad52-eec7-4401-b543-a71734a52de7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[''], [-1], [32.373741149902344]]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model([text], [translation('Чем закончилась сказка?', to_en, tokenizer_en)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnP1vzkLWyTf",
        "outputId": "f0bcf30b-b0eb-4adf-fb15-13791fbba48f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['seaweed'], [491], [1.2297698259353638]]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model([text], [translation('Что было разбито?', to_en, tokenizer_en)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fah_Xwtit5lq",
        "outputId": "74a4cf70-a6cf-478c-cc2b-0b75e56c7190"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'seaweed'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "o_t = model([text], [translation('Что было разбито?', to_en, tokenizer_en)])\n",
        "o_t[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0abzgoK9W4rX",
        "outputId": "ebfe6fbe-fbf3-49f3-ebc7-38395f560f55"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'seaweed'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translation('seaweed', to_ru, tokenizer_ru)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YwJVEWNIXx43",
        "outputId": "48d8ab5e-8563-4c8e-ae6f-d4396fdcba36"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'продовольствие'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translation('food', to_ru, tokenizer_ru)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lcpT_AQYNQl",
        "outputId": "152cc97b-9d30-4811-d694-d53c3fc61bfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yaweather\n",
            "  Downloading yaweather-1.2.2-py3-none-any.whl (29 kB)\n",
            "Collecting requests>=2.24\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp>=3.6 in /usr/local/lib/python3.7/dist-packages (from yaweather) (3.8.1)\n",
            "Collecting pydantic>=1.6\n",
            "  Downloading pydantic-1.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1 MB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.6->yaweather) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.6->yaweather) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.6->yaweather) (1.7.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.6->yaweather) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.6->yaweather) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.6->yaweather) (2.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.6->yaweather) (4.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.6->yaweather) (4.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.6->yaweather) (1.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24->yaweather) (2.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24->yaweather) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24->yaweather) (2022.6.15)\n",
            "Installing collected packages: requests, pydantic, yaweather\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.22.0\n",
            "    Uninstalling requests-2.22.0:\n",
            "      Successfully uninstalled requests-2.22.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.3\n",
            "    Uninstalling pydantic-1.3:\n",
            "      Successfully uninstalled pydantic-1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.6.0 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.18.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "fastai 2.7.7 requires torch<1.13,>=1.7, but you have torch 1.6.0 which is incompatible.\n",
            "fastai 2.7.7 requires torchvision>=0.8.2, but you have torchvision 0.7.0 which is incompatible.\n",
            "deeppavlov 0.17.4 requires pydantic==1.3, but you have pydantic 1.9.1 which is incompatible.\n",
            "deeppavlov 0.17.4 requires requests==2.22.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed pydantic-1.9.1 requests-2.28.1 yaweather-1.2.2\n"
          ]
        }
      ],
      "source": [
        "# !pip install yaweather"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Y3mPr4HQYDXD"
      },
      "outputs": [],
      "source": [
        "from geopy import geocoders\n",
        "from yaweather import Russia, YaWeather\n",
        "\n",
        "def get_weather(message):\n",
        "  try:\n",
        "    geolocator = geocoders.Nominatim(user_agent=\"telebot\")\n",
        "    latitude = geolocator.geocode(message.text).latitude\n",
        "    longitude = geolocator.geocode(message.text).longitude\n",
        "    y = YaWeather(api_key='8ae9d9be-3ea5-447f-aa8e-9f168b684b0a')\n",
        "    res = y.forecast((latitude, longitude))\n",
        "    forecast = f'cейчас {res.fact.temp} °C, oщущается как {res.fact.feels_like} °C'\n",
        "    bot.send_message(message.from_user.id, forecast)\n",
        "    # return forecast\n",
        "  except e:\n",
        "    bot.send_message(message.from_user.id, 'В этот раз я не справился, но я могу лучше...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PqPsgAwUYi_B",
        "outputId": "3c5f0205-0b0e-4288-dbfe-04dae5a5beb2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cейчас 20.0 °C, oщущается как 20.0 °C'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_weather('Санкт-Петербург')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhzPjYv5dNA5",
        "outputId": "b67e91dd-acfd-4d81-f140-dc8d64e75914"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Now: 21.0 °C, feels like 18.0 °C\n",
            "Condition: overcast\n"
          ]
        }
      ],
      "source": [
        "from yaweather import UnitedKingdom, YaWeather\n",
        "\n",
        "y = YaWeather(api_key='8ae9d9be-3ea5-447f-aa8e-9f168b684b0a')\n",
        "res = y.forecast(UnitedKingdom.London)\n",
        "\n",
        "print(f'Now: {res.fact.temp} °C, feels like {res.fact.feels_like} °C')\n",
        "print(f'Condition: {res.fact.condition}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Lesson_15_and_16.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
